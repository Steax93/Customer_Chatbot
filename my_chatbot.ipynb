{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of ChatBot\n",
    "> In this project I will show how you can easy create your ouwn ***Q/A*** customer support chat bot. Also will provide some helpfull function that could be usefull in your projects, or tasks win AI field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing necessary packages\n",
    "from google.cloud import bigquery\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import requests\n",
    "import datetime\n",
    "import time\n",
    "from google.oauth2.service_account import Credentials\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import DocArrayInMemorySearch, Chroma\n",
    "from langchain.document_loaders import TextLoader, PyPDFLoader, WebBaseLoader\n",
    "from langchain.chains import RetrievalQA, ConversationalRetrievalChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "import jsonlines\n",
    "import  jpype     \n",
    "import  asposecells     \n",
    "jpype.startJVM() \n",
    "from asposecells.api import Workbook\n",
    "from pydantic import BaseModel, Field\n",
    "import os\n",
    "import openai\n",
    "import sys\n",
    "sys.path.append('../..')\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from langchain.utils.openai_functions import convert_pydantic_to_openai_function \n",
    "import panel as pn\n",
    "import param\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.output_parsers.openai_functions import JsonOutputFunctionsParser,JsonKeyOutputFunctionsParser\n",
    "from typing import Optional, List\n",
    "from langchain.schema.runnable import RunnableLambda, RunnablePassthrough\n",
    "from langchain.tools import tool\n",
    "import wikipedia\n",
    "from langchain.tools.render import format_tool_to_openai_function\n",
    "from langchain.agents import AgentExecutor\n",
    "from langchain.agents.format_scratchpad import format_to_openai_functions\n",
    "from langchain.agents.output_parsers import OpenAIFunctionsAgentOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connect to OpenAI \n",
    "_ = load_dotenv(find_dotenv()) #read local .env file\n",
    "\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Loading access key\n",
    "key_path = \"serv_acc_key.json\"\n",
    "#Create credentials object\n",
    "credentials = Credentials.from_service_account_file(\n",
    "    key_path,\n",
    "    scopes = ['https://www.googleapis.com/auth/cloud-platform']\n",
    ")\n",
    "if credentials.expired:\n",
    "    credentials.refresh(Request())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Data Exctraction\n",
    "- 1.1. The first example will show how to extract data from Google Cloud.\n",
    "- 1.2. Second, how you can fetch data from Wikipedia depends on your request."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Exctraction from Google Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connect to BigQuery\n",
    "PROJECT_ID = 'praxis-window-402615'\n",
    "def run_bq_query(sql):\n",
    "\n",
    "    # Create BQ client\n",
    "    bq_client = bigquery.Client(project = PROJECT_ID, \n",
    "                                credentials = credentials)\n",
    "\n",
    "    # Try dry run before executing query to catch any errors\n",
    "    job_config = bigquery.QueryJobConfig(dry_run=True, \n",
    "                                         use_query_cache=False)\n",
    "    bq_client.query(sql, job_config=job_config)\n",
    "\n",
    "    # If dry run succeeds without errors, proceed to run query\n",
    "    job_config = bigquery.QueryJobConfig()\n",
    "    client_result = bq_client.query(sql, \n",
    "                                    job_config=job_config)\n",
    "\n",
    "    job_id = client_result.job_id\n",
    "\n",
    "    # Wait for query/job to finish running. then get & return data frame\n",
    "    df = client_result.result().to_arrow().to_pandas()\n",
    "    print(f\"Finished job_id: {job_id}\")\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating python dataframe\n",
      "Finished job_id: 009377c2-fee6-4c9d-9f09-b4877f241eac\n",
      "generating html dataframe\n",
      "Finished job_id: 97176d4a-d0f8-42ca-ba7e-3dfb8e1747fd\n",
      "generating r dataframe\n",
      "Finished job_id: e07b1c04-7ede-4646-9fa5-543e27936a8b\n",
      "generating css dataframe\n",
      "Finished job_id: 61144b45-64bc-4457-b41e-c76dd48c7192\n"
     ]
    }
   ],
   "source": [
    "#define list of programming language tags we want to query\n",
    "language_list = [\"python\",\"html\",\"r\",\"css\"]\n",
    "so_df = pd.DataFrame()\n",
    "\n",
    "for language in language_list:\n",
    "    \n",
    "    print(f\"generating {language} dataframe\")\n",
    "    \n",
    "    query = f\"\"\"\n",
    "    SELECT\n",
    "        CONCAT(q.title, q.body) as question,\n",
    "        a.body AS answer\n",
    "    FROM\n",
    "        `bigquery-public-data.stackoverflow.posts_questions` q\n",
    "    JOIN\n",
    "        `bigquery-public-data.stackoverflow.posts_answers` a\n",
    "    ON\n",
    "        q.accepted_answer_id = a.id\n",
    "    WHERE \n",
    "        q.accepted_answer_id IS NOT NULL AND \n",
    "        REGEXP_CONTAINS(q.tags, \"{language}\") AND\n",
    "        a.creation_date >= \"2020-01-01\"\n",
    "    LIMIT \n",
    "        500\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    language_df = run_bq_query(query)\n",
    "    language_df[\"category\"] = language\n",
    "    so_df = pd.concat([so_df, language_df], \n",
    "                      ignore_index = True) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How can I distribute member to it's role on py...</td>\n",
       "      <td>&lt;p&gt;Try:&lt;/p&gt;\\n&lt;pre class=\"lang-py prettyprint-o...</td>\n",
       "      <td>python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pydantic Inherited Class validation&lt;p&gt;I have 2...</td>\n",
       "      <td>&lt;blockquote&gt;\\n&lt;p&gt;The problem is that I can't s...</td>\n",
       "      <td>python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Why I can't get the shortest root to leaf heig...</td>\n",
       "      <td>&lt;p&gt;First some issues to make your code runnabl...</td>\n",
       "      <td>python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How to create from a 2-column DataFrame a Data...</td>\n",
       "      <td>&lt;p&gt;Try this:&lt;/p&gt;\\n&lt;pre&gt;&lt;code&gt;ndf = (df.set_ind...</td>\n",
       "      <td>python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>discord.py accept - if clause: .MissingRequire...</td>\n",
       "      <td>&lt;p&gt;Discord requires the parameter to be set un...</td>\n",
       "      <td>python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>css grid grows over 100% width with fr but not...</td>\n",
       "      <td>&lt;p&gt;&lt;strong&gt;Solution&lt;/strong&gt;:&lt;/p&gt;\\n\\n&lt;p&gt;Settin...</td>\n",
       "      <td>css</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>Javascript background Blur/Popup box transitio...</td>\n",
       "      <td>&lt;p&gt;Change your &lt;code&gt;toggle()&lt;/code&gt; function ...</td>\n",
       "      <td>css</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>How to change Bootstrap navbar color on scroll...</td>\n",
       "      <td>&lt;blockquote&gt;\\n&lt;p&gt;I Just tested this, and it wo...</td>\n",
       "      <td>css</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>Fadeout effect is not working using wow animat...</td>\n",
       "      <td>&lt;p&gt;You can add &lt;code&gt;animation-fill-mode: forw...</td>\n",
       "      <td>css</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>conditions ignored in change event jQuery?&lt;p&gt;S...</td>\n",
       "      <td>&lt;p&gt;Found two mistakes in your code &lt;/p&gt;\\n\\n&lt;ol...</td>\n",
       "      <td>css</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               question  \\\n",
       "0     How can I distribute member to it's role on py...   \n",
       "1     Pydantic Inherited Class validation<p>I have 2...   \n",
       "2     Why I can't get the shortest root to leaf heig...   \n",
       "3     How to create from a 2-column DataFrame a Data...   \n",
       "4     discord.py accept - if clause: .MissingRequire...   \n",
       "...                                                 ...   \n",
       "1995  css grid grows over 100% width with fr but not...   \n",
       "1996  Javascript background Blur/Popup box transitio...   \n",
       "1997  How to change Bootstrap navbar color on scroll...   \n",
       "1998  Fadeout effect is not working using wow animat...   \n",
       "1999  conditions ignored in change event jQuery?<p>S...   \n",
       "\n",
       "                                                 answer category  \n",
       "0     <p>Try:</p>\\n<pre class=\"lang-py prettyprint-o...   python  \n",
       "1     <blockquote>\\n<p>The problem is that I can't s...   python  \n",
       "2     <p>First some issues to make your code runnabl...   python  \n",
       "3     <p>Try this:</p>\\n<pre><code>ndf = (df.set_ind...   python  \n",
       "4     <p>Discord requires the parameter to be set un...   python  \n",
       "...                                                 ...      ...  \n",
       "1995  <p><strong>Solution</strong>:</p>\\n\\n<p>Settin...      css  \n",
       "1996  <p>Change your <code>toggle()</code> function ...      css  \n",
       "1997  <blockquote>\\n<p>I Just tested this, and it wo...      css  \n",
       "1998  <p>You can add <code>animation-fill-mode: forw...      css  \n",
       "1999  <p>Found two mistakes in your code </p>\\n\\n<ol...      css  \n",
       "\n",
       "[2000 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Checking what we have\n",
    "display(so_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Fetching from Wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a function that will fetch relevant information from wikipedia depends on user input\n",
    "@tool\n",
    "def search_wikipedia(query: str) -> str:\n",
    "    \"\"\"Run Wikipedia search and get page summaries.\"\"\"#Creating description that our llm will read\n",
    "    page_titles = wikipedia.search(query)#Scrap relevant information from wikipedia\n",
    "    summaries = []\n",
    "    for page_title in page_titles[: 3]:\n",
    "        try:\n",
    "            wiki_page =  wikipedia.page(title=page_title, auto_suggest=False)#Creating a page\n",
    "            summaries.append(f\"Page: {page_title}\\nSummary: {wiki_page.summary}\")#Appending all fetched info to our variable\n",
    "        except (\n",
    "            self.wiki_client.exceptions.PageError,\n",
    "            self.wiki_client.exceptions.DisambiguationError,\n",
    "        ):\n",
    "            pass\n",
    "    if not summaries:\n",
    "        return \"No good Wikipedia Search Result was found\"\n",
    "    return \"\\n\\n\".join(summaries)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Page: Machine learning\\nSummary: Machine learning (ML) is a field of study in artificial intelligence concerned with the development and study of statistical algorithms that can effectively generalize and thus perform tasks without explicit instructions. Recently, generative artificial neural networks have been able to surpass many previous approaches in performance. Machine learning approaches have been applied to large language models, computer vision, speech recognition, email filtering, agriculture and medicine, where it is too costly to develop algorithms to perform the needed tasks.The mathematical foundations of ML are provided by mathematical optimization (mathematical programming) methods. Data mining is a related (parallel) field of study, focusing on exploratory data analysis through unsupervised learning.ML is known in its application across business problems under the name predictive analytics. Although not all machine learning is statistically based, computational statistics is an important source of the field\\'s methods. \\n\\n\\n\\nPage: Adversarial machine learning\\nSummary: Adversarial machine learning is the study of the attacks on machine learning algorithms, and of the defenses against such attacks. A survey from May 2020 exposes the fact that practitioners report a dire need for better protecting machine learning systems in industrial applications.Most machine learning techniques are mostly designed to work on specific problem sets, under the assumption that the training and test data are generated from the same statistical distribution (IID). However, this assumption is often dangerously violated in practical high-stake applications, where users may intentionally supply fabricated data that violates the statistical assumption.\\nSome of the most common attacks in adversarial machine learning include evasion attacks, data poisoning attacks, Byzantine attacks and model extraction.\\n\\n\\n\\nPage: Quantum machine learning\\nSummary: Quantum machine learning is the integration of quantum algorithms within machine learning programs.The most common use of the term refers to machine learning algorithms for the analysis of classical data executed on a quantum computer, i.e. quantum-enhanced machine learning. While machine learning algorithms are used to compute immense quantities of data, quantum machine learning utilizes qubits and quantum operations or specialized quantum systems to improve computational speed and data storage done by algorithms in a program. This includes hybrid methods that involve both classical and quantum processing, where computationally difficult subroutines are outsourced to a quantum device. These routines can be more complex in nature and executed faster on a quantum computer. Furthermore, quantum algorithms can be used to analyze quantum states instead of classical data.Beyond quantum computing, the term \"quantum machine learning\" is also associated with classical machine learning methods applied to data generated from quantum experiments (i.e. machine learning of quantum systems), such as learning the phase transitions of a quantum system or creating new quantum experiments.Quantum machine learning also extends to a branch of research that explores methodological and structural similarities between certain physical systems and learning systems, in particular neural networks. For example, some mathematical and numerical techniques from quantum physics are applicable to classical deep learning and vice versa.Furthermore, researchers investigate more abstract notions of learning theory with respect to quantum information, sometimes referred to as \"quantum learning theory\".'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking if all working properly\n",
    "search_wikipedia({\"query\": \"Machine Learning\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Now that you have two functions that can be used for data extraction. Next, you need to pass this data into Vectorstore or Vectordb or you can simply save it in JSON or pdf file on your computer. Here is one example of how you can fast and easily store your data on your computer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Common way of storing your data to json format\n",
    "df = so_df.to_dict()\n",
    "with jsonlines.open(f'qa.json','w') as writer:\n",
    "    writer.write_all(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting our Json file to PD\n",
    "workbook = Workbook(\"qa.json\")\n",
    "workbook.save(\"qa.pdf\")\n",
    "jpype.shutdownJVM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function that will load your pdf file and create a Vector index store to which you could connect your llm\n",
    "def load_db(file,chain_type, k):\n",
    "    #load documents\n",
    "    loader=PyPDFLoader(file)\n",
    "    documents = loader.load()\n",
    "    #split documents\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size = 1000, chunk_overlap=150)\n",
    "    docs = text_splitter.split_documents(documents)\n",
    "    #define embedding\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "    # create vector database from data\n",
    "    db = DocArrayInMemorySearch.from_documents(docs,embeddings)\n",
    "    #define retriever\n",
    "    retriever = db.as_retriever(search_type =\"similarity\",search_kwargs = {\"k\":k})\n",
    "    #Create a chatbot chain. Memory is managed externally\n",
    "    qa = ConversationalRetrievalChain.from_llm(\n",
    "        llm = ChatOpenAI(model=\"gpt-3.5-turbo\",temperature=0),\n",
    "        chain_type=chain_type,\n",
    "        retriever=retriever,\n",
    "        return_source_documents = True,\n",
    "        return_generated_question = True,\n",
    "    )\n",
    "\n",
    "    return qa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Conclusion:** So now after you get two example how you can on a simple wat get a necessary data work with your chat let's show several tools that can be helpful for you, when you will build your customer chatbots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Function tools\n",
    " > Also you can create a different function depending on what kind of question the user will ask\n",
    "- Here I will create two different function \n",
    "- And show you how with the help of **pydantic** library you can build your function in a faster and simplest way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'ML_tools_search',\n",
       " 'description': 'Call this with an Machine learning code to extract any relevant information about Machine learning',\n",
       " 'parameters': {'title': 'ML_tools_search',\n",
       "  'description': 'Call this with an Machine learning code to extract any relevant information about Machine learning',\n",
       "  'type': 'object',\n",
       "  'properties': {'machine_learning': {'title': 'Machine Learning',\n",
       "    'description': 'machine learning code  to get information about',\n",
       "    'type': 'string'}},\n",
       "  'required': ['machine_learning']}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This function will fetch all relevant information about machine learning\n",
    "class ML_tools_search(BaseModel):\n",
    "    \"\"\"Call this with a Machine learning code to extract any relevant information about Machine learning\"\"\"\n",
    "    machine_learning: str = Field(description=\"machine learning code  to get information about\")\n",
    "ML_function = convert_pydantic_to_openai_function(ML_tools_search)\n",
    "ML_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'ArtistSearch',\n",
       " 'description': 'Call this to get the name of songs by a particular artist',\n",
       " 'parameters': {'title': 'ArtistSearch',\n",
       "  'description': 'Call this to get the name of songs by a particular artist',\n",
       "  'type': 'object',\n",
       "  'properties': {'artist_name': {'title': 'Artist Name',\n",
       "    'description': 'name of artist to look up',\n",
       "    'type': 'string'},\n",
       "   'n': {'title': 'N', 'description': 'number of results', 'type': 'integer'}},\n",
       "  'required': ['artist_name', 'n']}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Second function will fetch all relevant information about artist\n",
    "class ArtistSearch(BaseModel):\n",
    "    \"\"\"Call this to get the name of songs by a particular artist\"\"\"\n",
    "    artist_name: str= Field(description=\"name of artist to look up\")\n",
    "    n: int = Field(description=\"number of results\")\n",
    "\n",
    "artist_function = convert_pydantic_to_openai_function(ArtistSearch)\n",
    "artist_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The most popular type of machine learning currently is deep learning, which is a subset of artificial intelligence. Deep learning algorithms are designed to simulate the workings of the human brain and are particularly effective in tasks such as image and speech recognition, natural language processing, and recommendation systems.')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Insert all our function to one variable\n",
    "functions = [\n",
    "    ML_function,\n",
    "    artist_function\n",
    "]\n",
    "#Cre\n",
    "model = ChatOpenAI()\n",
    "model_with_functions = model.bind(functions=functions)\n",
    "model_with_functions.invoke(\"What type of ML most popular?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'name': 'ArtistSearch', 'arguments': '{\\n  \"artist_name\": \"Bon Jovi\",\\n  \"n\": 5\\n}'}})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_with_functions.invoke(\"what are the most popular songs by Bon Jovi?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Conclusion:** So By the previous line, you can see that when we called our model to find information about our artist the model called for our **ArtistSearch** function this is one example of using Functions depending on what kind of operations users ask of your model. Let's create a workable chain that will provide reasons and answer with help of functions that we have created previously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'artist_name': 'Bon Jovi', 'n': 5}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Exaple of using prompt + model + output \n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\"Your are assistant, and you need provide any relavant information\"),\n",
    "    (\"user\",\"{input}\")\n",
    "]\n",
    ")\n",
    "#Creating a LLM chain and provide output in Json format\n",
    "chain = prompt | model_with_functions | JsonOutputFunctionsParser()\n",
    "chain.invoke({\"input\":\"What type of musing singing Bon Jovi?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'people': [{'name': 'Joe', 'age': 30, 'gender': 'male'},\n",
       "  {'name': 'Martha', 'age': None, 'gender': None}]}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can also use extraction function, that will extract all relant information from a text/file\n",
    "# Here better to use JsonOutputKeyFunctionParser that will look only for relevant key inside text\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Extract the relevant information, if not explicitly provided do not guess. Extract partial info\"),\n",
    "    (\"human\", \"{input}\")\n",
    "])\n",
    "#Creating a function that will work as a person information extracter\n",
    "class Person(BaseModel):\n",
    "    \"\"\"Information about a person.\"\"\"\n",
    "    name: str = Field(description=\"person's name\")\n",
    "    age: Optional[int] = Field(description=\"person's age\")\n",
    "    gender: str = Field(description=\"person's gender\")\n",
    "\n",
    "class Information(BaseModel):\n",
    "    \"\"\"Information to extract.\"\"\"\n",
    "    people: List[Person] = Field(description=\"List of info about people\")\n",
    "\n",
    "#Creating necessary function by pydantic\n",
    "extraction_functions = [convert_pydantic_to_openai_function(Information)]\n",
    "#Applying function to model\n",
    "extraction_model = model.bind(functions=extraction_functions, function_call={\"name\": \"Information\"})\n",
    "#Building a Chain\n",
    "extraction_chain = prompt | extraction_model | JsonOutputFunctionsParser()\n",
    "#Calling chain\n",
    "extraction_chain.invoke({\"input\":\"Joe is 30, his mom is Martha\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Put all together:\n",
    "- Now I will all these techniques together in a real-world example\n",
    "- In this example, I will extract information from a blog post and provide a necessary format such as JSON or dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "LLM Powered Autonomous Agents | Lil'Log\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Lil'Log\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Posts\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Archive\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Search\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Tags\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "FAQ\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "emojisearch.app\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "      LLM Powered Autonomous Agents\n",
      "    \n",
      "Date: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "Table of Contents\n",
      "\n",
      "\n",
      "\n",
      "Agent System Overview\n",
      "\n",
      "Component One: Planning\n",
      "\n",
      "Task Decomposition\n",
      "\n",
      "Self-Reflection\n",
      "\n",
      "\n",
      "Component Two: Memory\n",
      "\n",
      "Types of Memory\n",
      "\n",
      "Maximum Inner Product Search (MIPS)\n",
      "\n",
      "\n",
      "Component Three: Tool Use\n",
      "\n",
      "Case Studies\n",
      "\n",
      "Scientific Discovery Agent\n",
      "\n",
      "Generative Agents Simulation\n",
      "\n",
      "Proof-of-Concept Examples\n",
      "\n",
      "\n",
      "Challenges\n",
      "\n",
      "Citation\n",
      "\n",
      "References\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general\n"
     ]
    }
   ],
   "source": [
    "#First loading data \n",
    "loader = WebBaseLoader(\"https://lilianweng.github.io/posts/2023-06-23-agent/\")\n",
    "documents = loader.load()#download data from website\n",
    "#fetching only  page content information\n",
    "doc = documents[0]\n",
    "page_content = doc.page_content[:1000]\n",
    "print(page_content[:1000])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'summary': 'The blog post discusses the concept of building autonomous agents using LLM (large language model) as its core controller. It mentions proof-of-concept demos and the potential of LLM beyond generating written content.',\n",
       " 'language': 'English',\n",
       " 'keywords': 'LLM, autonomous agents, planning, memory, tool use, proof-of-concept demos'}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating function that will provide a summary of the content,language and keywords of the content\n",
    "class Overview(BaseModel):\n",
    "    \"\"\"Overview of a section of text\"\"\"\n",
    "    summary: str= Field(description=\"Provide a concise summary of the content.\")\n",
    "    language: str = Field(description=\"Provide the language that the content is written in.\")\n",
    "    kewords: str = Field(description=\"Provide keywords related to the content\")\n",
    "\n",
    "overview_function = [\n",
    "    convert_pydantic_to_openai_function(Overview)\n",
    "]\n",
    "over_model = model.bind(\n",
    "    functions = overview_function,\n",
    "    function_call = {\"name\":\"Overview\"}\n",
    "\n",
    ")\n",
    "#Build prompt\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\"Extract the relenvant information, if not explicity provided do not quess. Exctract partial info\"),\n",
    "    (\"human\",\"{input}\")\n",
    "])\n",
    "extract_chain = prompt | over_model | JsonOutputFunctionsParser()\n",
    "\n",
    "#Calling our extractiong chain\n",
    "extract_chain.invoke({\"input\":page_content})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Also you can split your documents into chunck and exctrac information from there\n",
    "#You can add to your chain some data preparation methods that will give you opurtunity to exctract different type of informations\n",
    "#And you can combine two different chains and get final result\n",
    "# Here I propose to create a new function that will fetch relevant information from each papers inside our documents\n",
    "class Paper(BaseModel):\n",
    "    \"\"\"Information about papers mentioned.\"\"\"\n",
    "    title: str\n",
    "    author: Optional[str]\n",
    "\n",
    "\n",
    "class Info(BaseModel):\n",
    "    \"\"\"Information to extract\"\"\"\n",
    "    papers: List[Paper]\n",
    "\n",
    "\n",
    "paper_extraction_function = [\n",
    "    convert_pydantic_to_openai_function(Info)\n",
    "]\n",
    "extraction_model = model.bind(\n",
    "    functions=paper_extraction_function, \n",
    "    function_call={\"name\":\"Info\"}\n",
    ")\n",
    "\n",
    "\n",
    "#Creating prompt template\n",
    "template = \"\"\"A article will be passed to you. Extract from it all papers that are mentioned by this article. \n",
    "\n",
    "Do not extract the name of the article itself. If no papers are mentioned that's fine - you don't need to extract any! Just return an empty list.\n",
    "\n",
    "Do not make up or guess ANY extra information. Only extract what exactly is in the text.\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", template),\n",
    "    (\"human\", \"{input}\")\n",
    "])\n",
    "#First we will create Exctraction chain\n",
    "extraction_chain = prompt | extraction_model | JsonKeyOutputFunctionsParser(key_name=\"papers\")\n",
    "\n",
    "#Splitting text into a chunk\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_overlap =0)\n",
    "#Now we need to combine our splitting text(chunks) \n",
    "def flatten(matrix):\n",
    "    flat_list = []\n",
    "    for row in matrix:\n",
    "        flat_list += row\n",
    "    return flat_list\n",
    "#Will prepera our text into right format (e.g. \"Input\":\"text\")\n",
    "prep = RunnableLambda(\n",
    "    lambda x: [{\"input\": doc} for doc in text_splitter.split_text(x)]\n",
    ")\n",
    "#We call map in exctract_chain beause we will use several operations inside \n",
    "chain = prep | extraction_chain.map() | flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'Chain of thought (CoT; Wei et al. 2022)', 'author': ''},\n",
       " {'title': 'Tree of Thoughts (Yao et al. 2023)', 'author': ''},\n",
       " {'title': 'LLM+P (Liu et al. 2023)', 'author': ''},\n",
       " {'title': 'ReAct (Yao et al. 2023)', 'author': ''},\n",
       " {'title': 'Reflexion (Shinn & Labash 2023)', 'author': ''},\n",
       " {'title': 'Reflexion framework', 'author': 'Shinn & Labash'},\n",
       " {'title': 'Chain of Hindsight', 'author': 'Liu et al. 2023'},\n",
       " {'title': 'Algorithm Distillation', 'author': 'Laskin et al. 2023'},\n",
       " {'title': 'Algorithm Distillation', 'author': 'Laskin et al. 2023'},\n",
       " {'title': 'ED (expert distillation)', 'author': ''},\n",
       " {'title': 'RL^2', 'author': 'Duan et al. 2017'},\n",
       " {'title': 'MRKL: Modular Reasoning, Knowledge and Language',\n",
       "  'author': 'Karpas et al. 2022'},\n",
       " {'title': 'TALM: Tool Augmented Language Models',\n",
       "  'author': 'Parisi et al. 2022'},\n",
       " {'title': 'Toolformer', 'author': 'Schick et al. 2023'},\n",
       " {'title': 'HuggingGPT', 'author': 'Shen et al. 2023'},\n",
       " {'title': 'API-Bank (Li et al. 2023)', 'author': 'Li et al.'},\n",
       " {'title': 'ChemCrow (Bran et al. 2023)', 'author': 'Bran et al.'},\n",
       " {'title': 'Boiko et al. (2023)', 'author': 'Boiko et al.'},\n",
       " {'title': 'Generative Agents Simulation', 'author': 'Park, et al. 2023'},\n",
       " {'title': 'Park et al. 2023', 'author': 'Park'},\n",
       " {'title': 'Super Mario: A Platform Game for the Nintendo Entertainment System',\n",
       "  'author': 'Shigeru Miyamoto'},\n",
       " {'title': 'Model-View-Controller: A Design Pattern for Software Development',\n",
       "  'author': 'Trygve Reenskaug'},\n",
       " {'title': 'The Art of Game Design: A Book of Lenses',\n",
       "  'author': 'Jesse Schell'},\n",
       " {'title': 'Paper A', 'author': 'Author A'},\n",
       " {'title': 'Paper B', 'author': 'Author B'},\n",
       " {'title': 'Paper C', 'author': 'Author C'},\n",
       " {'title': 'Chain of thought prompting elicits reasoning in large language models',\n",
       "  'author': 'Wei et al.'},\n",
       " {'title': 'Tree of Thoughts: Deliberate Problem Solving with Large Language Models',\n",
       "  'author': 'Yao et al.'},\n",
       " {'title': 'Chain of Hindsight Aligns Language Models with Feedback',\n",
       "  'author': 'Liu et al.'},\n",
       " {'title': 'LLM+P: Empowering Large Language Models with Optimal Planning Proficiency',\n",
       "  'author': 'Liu et al.'},\n",
       " {'title': 'ReAct: Synergizing reasoning and acting in language models',\n",
       "  'author': 'Yao et al.'},\n",
       " {'title': 'Reflexion: an autonomous agent with dynamic memory and self-reflection',\n",
       "  'author': 'Shinn & Labash'},\n",
       " {'title': 'In-context Reinforcement Learning with Algorithm Distillation',\n",
       "  'author': 'Laskin et al.'},\n",
       " {'title': 'MRKL Systems A modular, neuro-symbolic architecture that combines large language models, external knowledge sources and discrete reasoning',\n",
       "  'author': 'Karpas et al.'},\n",
       " {'title': 'API-Bank: A Benchmark for Tool-Augmented LLMs',\n",
       "  'author': 'Li et al.'},\n",
       " {'title': 'HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in HuggingFace',\n",
       "  'author': 'Shen et al.'},\n",
       " {'title': 'ChemCrow: Augmenting large-language models with chemistry tools',\n",
       "  'author': 'Bran et al.'},\n",
       " {'title': 'Emergent autonomous scientific research capabilities of large language models',\n",
       "  'author': 'Boiko et al.'},\n",
       " {'title': 'Generative Agents: Interactive Simulacra of Human Behavior',\n",
       "  'author': 'Joon Sung Park, et al.'}]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(doc.page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Conclusion:**  So with the help of previous examples and tools, you can simply fetch a lot of useful information from ur data and save it or pass it to the LLM or your vector database, which can provide users with a good answer or generate a necessary answer or provide reasonable information to them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3. Creating a Testing Chat bot\n",
    "- In this step I will show you how you can create a simple chatbot with some additional tools inside, that can be used for different operations depending on what kind of query passes to the model from the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calling for extension\n",
    "pn.extension()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Define the input schema\n",
    "class OpenMeteoInput(BaseModel):\n",
    "    latitude: float = Field(..., description=\"Latitute of the location to fetch weather data for\")\n",
    "    longitude: float = Field(..., description=\"Longtitude of the location to fetch weather data for \")\n",
    "\n",
    "\n",
    "#Creating a function the will take parameters from the previous function as inputs and provide a necessary output based on these inputs\n",
    "@tool(args_schema=OpenMeteoInput)\n",
    "def get_current_temperature(latitude: float, longitude: float) -> dict:\n",
    "    \"\"\"Fetch current temperature for given coordinates.\"\"\"\n",
    "    BASE_URL = \"https://api.open-meteo.com/v1/forecast\"\n",
    "    #Parameters for the request\n",
    "    params = {\n",
    "        \"latitude\": latitude,\n",
    "        \"longitude\": longitude,\n",
    "        \"hourly\":\"temperature_2m\",\n",
    "        \"forecast_days\":1,\n",
    "    }\n",
    "    #Make the request\n",
    "    response = requests.get(BASE_URL,params=params)\n",
    "     \n",
    "    if response.status_code == 200:\n",
    "       results = response.json()\n",
    "    else:\n",
    "        raise Exception(f\"Api Requst failed with status code: {response.status_code}\")\n",
    "    \n",
    "    current_utc_time = datetime.datetime.utcnow()#fetching present time\n",
    "    #converting to a necessary format\n",
    "    time_list = [datetime.datetime.fromisoformat(time_str.replace('Z','+00:00')) for time_str in results['hourly']['time']]\n",
    "    #creating list of time/temperature\n",
    "    temperature_list = results['hourly']['temperature_2m']\n",
    "\n",
    "    #Finding a more nearest temperature for our present time from our previous created list\n",
    "    closest_time_index = min(range(len(time_list)), key = lambda i: abs(time_list[i] - current_utc_time))\n",
    "    #scrapping temperature \n",
    "    current_temperature = temperature_list[closest_time_index]\n",
    "\n",
    "    return print(f\"The current temperature is {current_temperature} C\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a function that will fetch relevant information from wikipedia depends on user input\n",
    "@tool\n",
    "def search_wikipedia(query: str) -> str:\n",
    "    \"\"\"Run Wikipedia search and get page summaries.\"\"\"#Creating description that our llm will read\n",
    "    page_titles = wikipedia.search(query)#Scrap relevant information from wikipedia\n",
    "    summaries = []\n",
    "    for page_title in page_titles[: 3]:\n",
    "        try:\n",
    "            wiki_page =  wikipedia.page(title=page_title, auto_suggest=False)#Creating a page\n",
    "            summaries.append(f\"Page: {page_title}\\nSummary: {wiki_page.summary}\")#Appending all fetched info to our variable\n",
    "        except (\n",
    "            self.wiki_client.exceptions.PageError,\n",
    "            self.wiki_client.exceptions.DisambiguationError,\n",
    "        ):\n",
    "            pass\n",
    "    if not summaries:\n",
    "        return \"No good Wikipedia Search Result was found\"\n",
    "    return \"\\n\\n\".join(summaries)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#You can also create your own function \n",
    "@tool\n",
    "def create_your_own(quesry: str) -> str:\n",
    "    \"\"\"This function can do whatever you would like once you fill it in\"\"\"\n",
    "    print(type(query))\n",
    "    return query[::-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assigned tools \n",
    "tools = [get_current_temperature,search_wikipedia,create_your_own]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating class that will work for us like a brain to our chatbot\n",
    "pn.extension()\n",
    "\n",
    "class cbfs(param.Parameterized):\n",
    "    \n",
    "    def __init__(self, tools, **params):\n",
    "        super(cbfs, self).__init__( **params)\n",
    "        self.panels = []\n",
    "        self.functions = [format_tool_to_openai_function(f) for f in tools]\n",
    "        self.model = ChatOpenAI(temperature=0).bind(functions=self.functions)\n",
    "        self.memory = ConversationBufferMemory(return_messages=True,memory_key=\"chat_history\")\n",
    "        self.prompt = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", \"You are helpful but sassy assistant\"),\n",
    "            MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "            (\"user\", \"{input}\"),\n",
    "            MessagesPlaceholder(variable_name=\"agent_scratchpad\")\n",
    "        ])\n",
    "        self.chain = RunnablePassthrough.assign(\n",
    "            agent_scratchpad = lambda x: format_to_openai_functions(x[\"intermediate_steps\"])\n",
    "        ) | self.prompt | self.model | OpenAIFunctionsAgentOutputParser()\n",
    "        self.qa = AgentExecutor(agent=self.chain, tools=tools, verbose=False, memory=self.memory)\n",
    "    \n",
    "    def convchain(self, query):\n",
    "        if not query:\n",
    "            return\n",
    "        inp.value = ''\n",
    "        result = self.qa.invoke({\"input\": query})\n",
    "        self.answer = result['output'] \n",
    "        self.panels.extend([\n",
    "            pn.Row('User:', pn.pane.Markdown(query, width=450)),\n",
    "            pn.Row('ChatBot:', pn.pane.Markdown(self.answer, width=450, styles={'background-color': '#F6F6F6'}))\n",
    "        ])\n",
    "        return pn.WidgetBox(*self.panels, scroll=True)\n",
    "\n",
    "\n",
    "    def clr_history(self,count=0):\n",
    "        self.chat_history = []\n",
    "        return \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Implementing frontend steps of our ChatBot \n",
    "b = cbfs(tools)\n",
    "\n",
    "inp = pn.widgets.TextInput( placeholder='Enter text here…')#Line of entering user input\n",
    "\n",
    "conversation = pn.bind(cb.convchain, inp)\n",
    "\n",
    "tab1 = pn.Column(\n",
    "    pn.Row(inp),\n",
    "    pn.layout.Divider(),\n",
    "    pn.panel(conversation,  loading_indicator=True, height=400),\n",
    "    pn.layout.Divider(),\n",
    ")\n",
    "\n",
    "dashboard = pn.Column(\n",
    "    pn.Row(pn.pane.Markdown('# QnA_Bot')),\n",
    "    pn.Tabs(('Conversation', tab1))\n",
    ")#Assigned name of chatbot and column from where you will see all input and output text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overal Conclusion:\n",
    "> In this project I showed you several tools:\n",
    "- 1) Techniques of extraction and preparing your data to be ready to go to your LLM or another Machine learning algorithm you can work with\n",
    "- 2) Secondary by creating functions and putting them into your model, you can provide the opportunity to determine which function is better for you depending on what kind of user query(input) will be. This is helpful when you want to build a more complex chatbot that can work not only on simple tasks such as Q/A but also provide summaries, analysis, or some operations on the data that you have.\n",
    "- 3) In the last part of this project. I created a chatbot with a simple interface by using **pn** library and showed how it can work in your local **Jupiter, vs code etc.** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
